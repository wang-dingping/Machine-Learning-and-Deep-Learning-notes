# Deep Learning 花书



## Chapter 5: 机器学习基础

学习算法的概念：对于某类任务T和性能度量P，一个计算机程序被认为可以从经验E中学习是指，通过经验E改进后，它在任务T上又性能度量P衡量的性能有所提升。

### 5.2 容量、过拟合、欠拟合

模型的**容量**是指模型**拟合各种函数的能力**。容量低的模型可能很难拟合训练集，会欠拟合。容量高的模型可能会过拟合。

**假设空间**是可选择为解决方案的函数集。

有多种方式可以改变模型的容量，可以改变输入特征的数目和加入这些特征对应的参数。容量不仅仅取决于模型的选择。模型规定了调整参数降低训练目标的时，学习算法可以从哪些函数族中选择函数。这被称为模型的**表示容量**。从这些函数中挑选最优函数是非常困难的优化问题。额外的限制因素，比如优化算法的局限性，意味着学习算法的有效容量可能小于模型族的表示容量。

### 5.4 估计、偏差和方差

#### 5.4.1点估计、函数估计

一般，某个参数或者向量参数是我们的预测目标。

点估计是数据点的任意函数：

$\boldsymbol{\hat{\theta}}_m=g(\boldsymbol{x^{(1)}},...,\boldsymbol{x}^{(m)})$

#### 5.4.2 偏差与方差

估计的偏差被定义为

$bias(\boldsymbol{\hat{\theta}}_m)=E(\boldsymbol{\hat{\theta}}_m)-\boldsymbol{\theta}$

其中期望作用在所有数据（看作从随机变量取样得到的）上，$\boldsymbol{\theta}$是用于定义数据生成分布的$\theta$的真实值。

**偏差和方差的区别**：

偏差：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据。

方差：描述的是预测值的变化范围，离散程度。方差越大，数据分布越分散。

<img src="C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200215162613892.png" alt="image-20200215162613892" style="zoom:50%;" />

当一个学习器学习能力很强，能把训练数据特征都能学到，甚至一些训练数据独有的特征，它在训练结果中，表现很好，输出结果和真实值都很接近，这就是偏差很小；反而言之，一个学习器学习能力很弱，训练时，它的预测结果离真实值差的很多，这就是偏差很大。

但是，在测试集中，由于学习器学习到了一些训练数据独有而测试数据没有的特征，这就导致了其输出结果变化很大，这就是方差很大；弱的学习器由于没有学到很多特征，所以对不一样的数据集的输出之间差距不大，这就是方差很小。

总而言之，学习能力不行造成的误差就是偏差，学习能力太强造成的误差就是方差。

#### 5.4.3 权衡偏差和方差的方法

当我们可以在一个偏差更大的估计和一个方差更大的估计中进行选择时，我们应该如何选择？判断这种权衡最常用的方法是交叉验证。另外，我们也可以比较这些估计的均方误差(mean squared error, MSE)：
$MSE=Bias(\hat{\theta}_m)^2+Var(\hat{\theta}_m)$

MSE度量着**估计**和**真实参数**$\theta$之间的**平方误差**的总体期望偏差。MSE估计包含了偏差和方差。

理想的估计具有较小的MSE或是在检查中稍微约束它们的偏差和方差。

偏差和方差的关系与机器学习容量、欠拟合、过拟合的概念紧密相联。

### 5.5 最大似然估计

最大化关于参数$w$的对数似然和最小化均方误差会得到相同的参数估计$w$。这验证了MSE可以用于最大似然估计。

当样本数目越大，就收敛率而言，最大似然是最好的渐进估计。

### 5.6 贝叶斯估计

频率派的最大似然和统计派的贝叶斯的两大区别：

- 频率派解决给定点估计$\theta$的不确定性的方法是评估方差，估计的方差评估了观测数据重新从观测数据中采样后，估计可能如何变化；而贝叶斯排解决该方法的手段是积分，这往往会防止过拟合。
- 贝叶斯考虑了先验分布。先验能够影响概率质量密度**朝参数空间中偏好先验的区域偏移**。实践中，先验通常表现为偏好更简单或更光滑的模型。

**当训练数据很有限时，贝叶斯方法通常泛化得更好，但是当训练样本数目很大时，通常会有很大的计算代价。**

#### 5.6.1 最大后验估计 MAP

MAP估计选择后验概率最大的点

$\boldsymbol{\theta}_{MAP}=argmax_\boldsymbol{\theta} p(\boldsymbol{\theta}|x)$

MAP贝叶斯推断的优势是能够利用来自先验的信息，这些信息无法从训练数据中获得。该附加信息有助于减少最大后验点估计的方差。然而这个优点的代价是增加了偏差。



**KL三度和交叉熵**

对于同一个随机变量$x$有两个单独的概率分布$P(x)和Q(x)$，使用KL散度来衡量这两个分布的差异：

$D_{KL}(P||Q)=E_{X-P}[logP(x)-logQ(x)]$

一个和KL散度密切联系的量是交叉熵

$H(P,Q)=H(P)+D_{KL}(P||Q)=-E_{X-P}[logQ(x)]=-\sum_{i=1}^np(x_i)log(q(x_i))$

在机器学习中，我们常常使用KL散度来评估predict和label之间的差别，但KL散度是一个常量，所以我们常常将后半部分的交叉熵作为损失函数。

交叉熵更适合分类问题，是因为其有利于基于梯度下降的学习。https://zhuanlan.zhihu.com/p/61944055





# Part II Deep Networks: Modern Practices

This part of the book summarizes the state of modern deep learning as it is used to solve practical applications.

This part focuses only on those approaches that are essentially working technologies that are already used heavily in industry.

We begin by describing the feedforward deep network model that is used to represent these functions. Next, we present advance techniques for regularization and optimization of such models. Then, CNN and RNN. Finally, we present general guidelines for the practical methodology involved in designing, building, and configuring and application involving deep learning, and review some of the applications of deep learning.

## Chapter 6: Deep Feedforward Networks

These model are called feedforward because information flows through the function being evaluated from $$\boldsymbol{x}$$, through the intermediate computations used to define $$f$$, and finally to the output $$\boldsymbol{y}$$. There are no feedback connections in which outputs of the model are fed back into itself. When feedforward neural networks are extended to include feed back connections, they are called recurrent neural networks.

### 6.2 基于梯度的学习

使用梯度下降训练神经网络与训练其他任何模型并没有太大区别。计算梯度对于神经网络会稍微复杂一些，但仍然可以很高效而精确地实现。构建整个学习算法，包括**指定一个优化过程、代价函数、一个模型族**。

#### 6.2.1 代价函数

深度神经网络中的一个重要方面是代价函数的选择。

##### 6.2.1.1 使用最大似然学习条件分布

复习：最大似然估计是一种统计方法，它用来求一个样本集的相关概率密度的参数。根据已知样本，去求解概率密度的参数。最大似然估计的一般求解步骤，是先写出似然函数，似然函数为每个样本概率积，似然函数代表的是实验结果的概率。然后，求使得实验结果概率值最大的参数，通过寻找似然函数最大值，也就是使得导数等于零。

大多数现代的神经网络使用最大似然来训练。这意味着代价函数就是负的对数似然（训练目标是求得使代价函数最小的参数），它与训练数据和模型分布间的交叉熵等价。

最大似然来表示代价函数的有优点是，它减轻了为每个模型设计代价函数的负担。明确了模型的概率密度函数（这个是连续变量的名称，我忘了离散的怎么说了）$p(x|y)$，就能够自动确定代价函数。

另一个优势是，**能够避免代价函数梯度过小的问题**。因为如果梯度过小，学习算法的预测性就很低，很难求解代价函数最小值。负的对数似然函数能够解决某些激活函数的饱和性质带来的低梯度的问题，比如指数函数的负值会饱和。

##### 6.2.1.2 学习条件统计量

#### 6.2.2 输出单元

代价函数的选择与输出单元的选择紧密相连。**选择输出的形式决定了交叉熵函数的形式。**

##### 6.2.2.1 用于高斯输出分布的线性单元



##### 6.2.2.2 用于伯努利输出分布的sigmoid单元

针对两个类的分类问题可以归结为这种形式的输出单元。

基于使用sigmoid输出单元结合最大似然来实现的。

logistic sigmoid:

$\sigma(x)=\frac{1}{1+e^{-x}}$

![image-20200203235728538](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200203235728538.png)

sigmoid单元定义为：

$\hat{y}=\sigma(\mathbf{\boldsymbol{w}}^\top\boldsymbol{h}+b)$

我们可以将sigmoid单元看成两个部分。第一个部分是线性层，$z=\mathbf{\boldsymbol{w}}^\top\boldsymbol{h}+b$，第二层是使用sigmoid激活函数将$z$转化称概率。



##### 6.2.2.3 用于n重伯努利输出分布的softmax单元

softmax函数最常用作分类器的输出，来表示n个不同类上的概率分布。



### 6.3 隐藏单元

如何选择隐藏单元的类型，这些隐藏单元用在模型的隐藏层中。

隐藏单元的设计是一个非常活跃的研究领域，并且还没有许多明确的指导性理论原理。

**整流线性单元**是隐藏单元极好的默认选择。我们这里描述了对于每种隐藏单元的一些基本直觉。这些直觉可以用来建议我们何时尝试一些单元。

#### 6.3.1 整流线性单元ReLU及其扩展

整流线性单元使用激活函数$g(z)=max\{0,z\}$。

整流线性单元易于优化，因为它们和线性单元非常类似。

整流线性单元通常作用于**仿射变换**之上：

$\boldsymbol{h}=g(\mathbf{\boldsymbol{w}}^\top\boldsymbol{h}+b)$

整流线性单元有三个扩展，用于确保它们能在各个位置都能接收到梯度，因为ReLU在z小于0时，没有激活，导数为0。

- 绝对值整流
- 渗漏整流线性单元
- 参数化整流线性单元

**maxout**单元进一步扩展了整流线性单元。

#### 6.3.2 logistic sigmoid与双曲正切函数

在引入整流线性单元之前，大多数神经网络使用logistic sigmoid激活函数

$g(z)=\sigma(z)$

或者是双曲正切函数

$g(z)=tanh(z)$

通过sigmoid的曲线可以看出，在z的绝对值很大或者很小时，函数都处于饱和状态。这种广泛的饱和性，使得基于梯度的学习变得非常困难。因此，现在**不鼓励将它们用作前馈网络中的隐藏单元**。但是在输出部分，只要能找到代价函数抵消sigmoid的饱和性，就可以基于梯度的学习兼容。

双曲正切激活函数通常要比sigmoid表现更好。

sigmoid激活函数在除了前馈网络意外的情景中更为常见。

#### 6.3.3 其他隐藏单元

隐藏单元设计仍然是一个活跃的研究领域，许多有用的隐藏单元类型仍有待发现。

### 6.4 架构设计

神经网络设计的另一个关键点是确定它的架构。**架构**一词是指网络的整体结构：它应该有多少单元，以及这些单元应该如何连接。

在前馈网络的链式架构中，主要的架构考虑是选择网络的深度和每一层的宽度。**对于一个具体的任务，理想的网络架构必须通过实验，观测在验证集上的误差来找到**。

#### 6.4.1 万能近似性质和深度

线性模型，有益于训练，但是不能处理非线性函数。往往在机器学习中，我们希望系统去学习非线性函数。具有隐藏层的前馈网络提供了一种万能近似框架。具体来说，**万能近似定理**表明，一个前馈神经网络如果具有线性输出层和至少一层具有任何一种“挤压”性质的激活函数（比如sigmoid激活函数）的隐藏层，只要给予网络足够数量的隐藏单元，**它可以以任意的精度来近似任何从一个有限维空间刀另一个有限维空间的Borel可测函数**。前馈网络的导数也可以任意好地来近似函数的导数。

万能近似定理意味着无论我们试图学习什么函数，我们知道一个大的MLP一定能表示这个函数。但这不意味着训练算法能够学到这个函数。这个定理说明了，存在足够大的网络能够让我们以任意精度近似borel可测函数，但是并没有说这个网络有多大。在最坏的情况下，可能需要指数数量的隐藏单元。

总之，**具有单层的前馈网络足以表示任何函数，但网络层可能大的不可实现，并且无法正确地学习和泛化**。在很多情况下，**更深的模型**能够减少表示期望函数所需的单元的数量，并可以减少泛化误差。

增加模型的深度，说明了一个非常普遍的信念，即我们想要学得的函数应该是几个更加简单的函数的组合。下面两图证明了模型深度的有效性。

![image-20200204162934527](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200204162934527.png)

![image-20200204163002673](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200204163002673.png)

#### 6.4.2 其他架构上的考虑

到目前为止，我们都将神经网络描述成层的简单链式结构，主要的考虑因素是**网络的深度和每层的宽度**。但在实践中，神经网络显示出相当的多样性。

许多神经网络架构已经被开发用于特定的任务。卷积神经网络用于机器视觉，前馈网络推广到用于序列处理的循环神经网络。

架构的设计还需要考虑如何将层与层之间连接起来。在卷积网络中，使用了非常有效的稀疏连接的专用模式。

## Chapter 7: 深度学习中的正则化

机器学习中的一个核心问题是设计不仅在训练数据上表现号，而且能在新输入上泛化好的算法。在机器学习中，许多策略被显式地设计来减少测试误差。这些策略被统称为正则化。事实上，开发更有效的正则化策略已成为本领域最主要的研究工作之一。

**正则化是指**修改学习算法，使其降低泛化误差而非训练误差。正则化是机器学习领域的中心问题之一，只有优化能够与其重要性相提并论。根据第五章，我们可以通过两种方式控制算法性能，一是允许使用的函数种类，二是这些函数的数量。对于函数的数量，即模型容量，表示对函数的偏好是更普遍的方法。

### 7.1 参数范数惩罚



### 7.11 Bagging 和其他集成方法

Bagging是通过结合几个模型降低泛化误差的技术。主要想法是分别训练几个不同的模型，然后让所有模型表决测试样例的输出。这是机器学习中常规策略的一个例子，被称为模型平均。采用这种策略的技术被称为集成方法。

**模型平均**凑效的原因是不同的模型通常不会在测试集上产生完全相同的误差。

Bagging 涉及构造k个不同的数据集。每个数据集从原始数据集中重复采样构成（即会出现通过个数据集中有相同样本），和原始数据具有相同数量的样例。这就意味着每个数据集以高概率缺少一些来自原始数据集的例子（占1/3），还包含若干重复的例子（占2/3）。模型i在数据集i上训练。每个数据集所含样本的差异导致了训练模型之间的差异。

下图展示Bagging如何工作的草图。

![image-20200208230526449](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200208230526449.png)

对于一个数字8检测器，原始数据集为968。Bagging创造出两个数据集。在第一个数据集868中，检测器学习到只要是上面有个o，就是8；而在第二个数据集998中，检测器则学习到下面有o的数字是8。平均这两个模型的输出，就能得到鲁棒的检测器。

模型平均是一个**减少泛化误差的非常强大可靠的方法**。机器学习比赛中取胜算法通常是使用超过十几种模型平均的方法。

### 7.12 Dropout

Dropout提供了正则化一大类模型的方法，计算方便而功能强大。Dropout可以被认为集成大量神经网络的使用Bagging的方法。由于Bagging需要训练多个模型，这非常耗费时间和内存。Dropout提供了一种廉价的Bagging集成近似，能够训练和评估指数级数量的神经网络。

### 7.13 对抗训练

在一些精度能够达到人类水平的模型，在真实数据点附近的构造数据点中，这些模型错误率能够达到100%。通过对抗训练，能够减少这种错误率。

对抗训练有助于体现积极正则化与大型函数族结合的力量。纯粹的线性模型，如逻辑回归，由于它们被限制为线性而无法抵抗对抗样本。而神经网络能够将函数从接近线性转化为局部近似恒定，从而可以灵活地捕获到训练数据中的线性趋势同时学习抵抗局部扰动。

对抗样本也提供了一种实现**半监督学习**的方法。在于数据集中的标签不相关联的点$\boldsymbol{x}$处，**模型本身为其分配一些标签**$\hat{y}$。模型的标记$\hat{y}$未必是真正的标签，但如果模型是高品质的，那么$\hat{y}$提供正确标签的可能性很大。我们可以搜索一个对抗样本$\boldsymbol{x'}$，导致分类器输出一个标签$y'$且$y'\neq{\hat{y}}$。不使用标签，而是由训练好的模型提供标签产生的对抗样本被称为**虚拟对抗样本**。

## Chapter 8: 深度模型的优化

本章主要关注这一类特定的优化问题：寻找神经网络上的一组参数$\boldsymbol{\theta}$，它能显著地降低代价函数$J(\boldsymbol{\theta})$，该代价函数通常包括整个训练集上的性能评估和额外的正则化项。

### 8.1 学习和纯优化有什么不同

用于深度模型训练的优化算法与传统的优化算法在几个方面有所不同。

* 机器学习通常是间接优化损失函数，而不是直接优化性能度量P

#### 8.1.1 经验风险最小化

机器学习算法的目标是降低数据生成分布的泛化误差期望，这个数据量称为**风险**。但是机器学习中我们并不知道数据真实的分布，我们只知道训练集中的样本。将机器学习问题转化会一个优化问题的最简单的方法是最小化训练集上的期望损失，用训练集上的经验分布替代真实分布，并**最小化经验风险**。

在这里，我们不直接优化风险，而是优化经验风险。

然而，经验风险最小化很容以导致过拟合。高容量的模型容易简单地记住训练集。在深度学习中，**我们很少使用经验风险最小化**，反而，我们会用一个稍有不通过的方法。

#### 8.1.2 代理损失函数和提前终止

#### 8.1.3 批量算法和小批量算法

**批量梯度下降**指使用全部训练集

### 8.2 神经网络优化中的挑战

#### 8.2.1 病态

Hessian矩阵$H$的病态。

病态问题一般被认为存在于神经网络训练过程中。病态体现在随机梯度下降会卡在某些情况，此时即使很小的更新步长也会增加代价函数。

#### 8.2.2 局部极小值

#### 8.2.3 高原、鞍点和其他平坦区域

#### 8.2.4 悬崖和梯度爆炸

### 8.3 基本算法

#### 8.3.1 随机梯度下降SGD

随机梯度下降及其变种很可能是一般机器学习中应用最多的优化算法，特别是在深度学习中。按照数据生成分布抽取m个小批量样本，通过计算他们梯度均值，我们可以得到梯度的无偏估计。

SGD算法中的一个关键参数是学习率。在实践中，有必要随着时间推移逐渐降低学习率，因此我们将第k步迭代的学习率记作$\epsilon_k$。

实践中，一般会**线性衰减学习率直到第$\tau$次迭代：**

$\epsilon_k=(1-\alpha)\epsilon_0+\alpha\epsilon_{\tau}$

$\alpha=\frac{k}{\epsilon}$

通常，$\tau$被设置为需要遍历训练集几百次的迭代次数。$\epsilon_{\tau}$设置为$\epsilon_0$的1%。主要问题是如何设置$\epsilon_0$。通常，就总训练时间和最终代价值而言，最优初始学习率会**高于大约迭代100次后达到最佳效果的学习率**。因此通常最好是检测最早的几轮迭代，选择一个比在效果上表现最佳的学习率更大的学习率，但不能太大导致严重的震荡。

#### 8.3.2 动量

随机梯度很受欢迎，但是其学习过程有时会很慢。动量方法旨在加速学习，特别是处理高曲率、小但一致的梯度，或是带噪声的梯度。动量算法积累了之前梯度指数级衰减的移动平均，并继续沿该方向继续移动。

## Chapter 9: 卷积网络

### 9.2 动机

卷积运算通过三个重要的思想帮助改进机器学习系统：**稀疏交互**、**参数共享**、**等变表示**。另外，卷积提供了一种大小可变输入的方法。

在传统神经网络中，我们使用矩阵乘法来建立输入与输出的连接关系。其中，参数矩阵每个单独参数都描述了一个输入单元和一个输出单元之间的交互。这意味着每个输出单元与输出单元都产生交互。然而卷积网络具有**稀疏交互**或者**稀疏权重**的特征。将卷积核比图像本身小许多，模型自身的参数也相对少了许多，输入输出之间的交互因此减少。

**参数共享**是指在一个模型的多个函数中使用相同的参数。这意味着我们只需要学习一个参数的集和，而不是在输入的每一个位置都需要学习一个单独的参数集和。

## Chapter 10: 序列建模：循环神经网络

循环神经网络专门用来处理序列。

### 10.2 循环神经网络

最常用的设计模式：

![image-20200130120920852](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200130120920852.png)

每个时间步都有输出，并且隐藏单元之间有循环连接的循环网络。其更新方程如下：
$\boldsymbol{a^{(t)}=\boldsymbol{b}+\boldsymbol{Wh^{(t-1)}}+Ux^{(t)}}$

$\boldsymbol{h^{(t)}}=tanh(\boldsymbol{a^{(t)}})$

$\boldsymbol{o^{(t)}}=\boldsymbol{c}+V\boldsymbol{h^{(t)}}$

#### 10.2.1 导师驱动过程和输出循环网络

相比于上述的循环网络模式，还有另一种模式，即当前时刻输出到下一个时刻的隐藏单元有循环网络（隐藏单元之间不直接相连）。

消除了隐藏单元之间的循环的优点在于，求损失时，不需要一步步反向传播求解，可以多个时间点并行计算，在各时刻求解梯度。

![image-20200130122114603](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200130122114603.png)

在导师驱动过程中，在训练时，当前时刻输出的真值$y^{(t-1)}$与下一时刻的隐藏单元$h^{(t)}$连接，而不是当前时刻的输出$o^{(t-1)}$与下一时刻隐藏单元$h^{(t)}$连接；在测试时，由于没有真值，我们才会用当前时刻输出$o^{(t-1)}$与下一时刻的隐藏单元$h^{(t)}$连接。

#### 10.2.2 计算循环神经网络的梯度



### 10.10 长短期记忆和其他门控RNN

世纪应用中最有效的序列模型称为**门控RNN**。包括基于**长短期记忆的LSTM**和**基于门控循环单元的网络GRU**。

#### 10.10.1 LSTM 

![image-20200130225139146](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200130225139146.png)

#### 10.10.2 其他门控RNN

![image-20200130225239799](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200130225239799.png)



## Chapter 11: 实践方法论

一个优秀的机器学习实践者还需要知道如何针对具体应用挑选一个合适的算法以及如何监控，并根据实验反馈改进机器学习系统。在机器学习日常开发中，实践者需要决定是否收集更多的数据、添加或删除正则化项、改进模型的优化、改进模型的近似推断或调试模型的软件实现。

可供参考的几个实践设计流程：

- 确定目标-使用什么样的**误差度量**，并为此误差度量**指定目标值**。这些目标和误差度量取决于该应用旨在解决的问题。
- 尽快建立一个端到端的工作流程，包括估计合适的**性能度量**。
- 搭建系统，并确定**系统瓶颈**。检查哪个部分性能差于预期，以及是否因为过拟合、欠拟合，或者数据软件缺陷造成的。
- 根据具体观察反复地进行增量式的改动，如收集新数据、调整超参数或者改进算法。

### 11.1 性能度量

确定目标，即，使用什么误差度量，是必要的第一步，因为误差度量将指导接下来所有工作。同时我们也应该了解大概能得到什么级别的目标性能。科研中，目标通常是在某个确定基准下探讨哪个算法更好，一般会固定训练集，不允许收集更多的数据。

如何确定合理的性能期望？在学术界，通常我们可以根据先前公布的基准结果来估计预期错误率。除了需要考虑性能度量之外，我们还需要考虑度量的选择。根据周志华教授的《机器学习》，错误率与精度、查准率、查全率与F1、PR曲线、ROC、代价敏感错误率等等。

在一些应用中，由于某种原因，机器无法正确识别结果，会拒绝做出判断，让人类解决。在这种情况下，一种自然的性能度量是**覆盖**。覆盖是机器学习系统能够产生响应的样本所占的比率。如果覆盖太低，那么人类的工作量就会大大增加，失去机器处理问题的意义。

### 11.2 默认的基准模型

确立性能度量和目标之后，任何实际应用的下一步是尽快建立一个合理的端到端的系统。在本节，会提供了关于不同情况下使用哪种算法作为第一基准方法的推荐。

首先，根据数据的结构选择一类合适的模型。如果项目是以固定大小的向量作为输入的监督学习，那么可以使用全连接的前馈网络。如果输入已知的拓扑结构（例如，输入的是图像），那么可以使用卷积网络。在这些情况下。刚开始可以使用的某些分段线性单元（ReLU或者其扩展，如Leaky ReLU、PReLU和maxout）。如果输入或者输出是一个序列，可以使用门控循环网络。

其次，设置逐渐衰减的学习率以及动量SGD是优化算法一个合理选择（如Adam算法）。然后决定是否进行批标准化、设置Dropout.

在模型的选择上，我们可以走捷径。如果我们的任务和另一个被广泛研究的任务相似，那么通过复制先前研究中已知性能良好的模型和算法，可能会得到很好的结果。

监督学习还是无监督学习？这个问题跟特定领域有关。在某些领域，比如自然语言处理，能够大大受益于无监督学习技术。在其他领域，如计算机视觉，目前无监督学习并没有带来益处。

### 11.3 决定是否收集更多数据

首先，确定训练集上的性能是否可接受。如果模型在训练集上的性能就很差，学习算法都不能在训练集上学习出良好的模型，那么就没必要收集更多的数据。反之，可以尝试增加更多的网络层或者每层增加更多的隐藏单元，以增加模型的规模。此外，也可以尝试调整学习率等超参数的措施来改进学习算法。如果更大的模型和仔细调试的优化算法效果不佳，那么问题可能源自训练数据的质量。数据可能含有太多噪声，或是可能不包含预测输出所需的正确输入。这意味着我们需要重新开始，收集更干净的数据或收集特征更丰富的数据集。

如果训练集上的性能是可接受的，那么我们开始度量测试机上的性能。如果测试集上的性能也是可以接受的，那么就顺利完成了。如果测试集上的性能比训练集要差得多，那么收集更多数据是最有效的解决方案之一。另一个方案是，降低模型的大小或是改进正则化（调整超参数，如权重衰减系数，或是加入正则化策略，如Dropout）。

在决定是否收集更多数据时，也需要确定收集多少数据。如下图，绘制的曲线显示训练集规模和泛化误差之间的关系是很有帮助的。根据走势延申曲线，可以预测还需要多少训练数据来达到一定的性能。

![image-20200114121218209](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200114121218209.png)

### 11.4 选择超参数

大部分深度学习算法都有许多超参数来控制不同方面的算法表现。有些超参数会影响算法运行时间和存储成本，有些会影响学习到的模型质量以及泛化能力。

#### 11.4.1 手动调整超参数

手动设置超参数，我们必须了解超参数、训练误差、泛化误差和计算资源之间的关系。这需要切实了解一个学习算法有效容量的基础概念，参考第五章。

手动搜索超参数的主要目标是**调整模型的有效容量**以匹配任务的复杂性。有效容量受限于3个因素：模型的表示容量、学习算法成功最小化训练模型代价函数的能力，以及代价函数和训练过程正则化模型的程度。具有更多网络层、每层有更多隐藏单元的模型具有较高的表示能力-能够表示更复杂的函数。然而，如果训练算法不能找到某个合适的函数来最小化训练代价，或是正则化项排除了这些合适的函数，那么即使模型表达能力较高，也不能学习出合适的函数。

当泛化误差以某个超参数为变量，作为函数绘制出来时，通常会表现为U型曲线。如图5.3所示，横坐标超参数为容量，纵坐标会误差，红色的线是拟合边界，左边是欠拟合，右边是过拟合。从曲线形状可以看出，当容量小时，误差正如我们所预料的一样非常高，泛化误差由于训练误差较大而很高；当超参数-容量很大时，泛化误差很高，这是因为训练误差和测试误差之间的差距较大；最优的模型容量位于图中的红线位置，在这里能够达到理论上最低的泛化误差。

![image-20200115120213398](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200115120213398.png)

对于某些超参数，当超参数数值太大时，会发生过拟合。例如中间层隐藏单元的数量，增加数量能提高模型的容量，**容易发生过拟合**。对于某些超参数，当数值太小时，也会发生过拟合。例如，权重衰减系数允许为零，此时学习算法具有最大的有效容量，反而容易过拟合。

并非所有超参数都能对应着完整的U型曲线。很多超参数是离散的，如中间层单元数目或者是maxout单元中线性元件的数目，这种情况只能沿曲线探索一些点。有些超参数是二值的。

学习率可能是最重要的超参数。如果你只有时间调整一个超参数，那就调增学习率。相比于其他超参数，学习率以一种更复杂的方式控制模型的有效容量-当学习率合适优化问题时，模型的有效容量最高，此时学习率是正确的。**学习率关于训练误差**具有U型曲线，如图11.1所示。当学习率过大时，梯度下降可能会不经意地增加而非减少训练误差。当学习率是最佳数值的两倍时，会发生上述情况。就像图中的右侧突然垂直上升的曲线一样，误差会突然飙升。学习率太小，训练不仅慢，而且可能永久停留在一个很高的训练误差上。

调整学习率外的其他参数时，需要**同时监视训练误差和测试误差**，以判断模型是否过拟合或欠拟合，然后适当调整其容量。

![image-20200115182210261](C:\Users\ASUS\AppData\Roaming\Typora\typora-user-images\image-20200115182210261.png)

如果训练集错误率大于目标错误率，那么只能增加模型容量以改进模型。如果没有使用正则化，并且确信优化算法正确运行，那么有必要添加更多的网络层或隐藏单元。然而，这会增加模型的计算代价。

如果测试集错误率大于目标错误率，那么可以采取两种方法。测试误差=训练误差和测试误差的差+训练误差，即测试误差 = （测试误差-训练误差）+训练误差。当训练误差较小（这意味着容量较大），测试误差主要取决于训练误差和测试误差之间的差距时，通常神经网络效果最好。此时目标是缩小这一差距，使训练误差的增长速率不快于差距减小的速率。要减小这个差距，我们可以改变正则化超参数，以减小有效的模型容量，如添加Dropout或者权重衰减的策略。通常，最佳性能来自正则化得很好的大规模模型，比如使用Dropout的神经网络。

表 11.1 各种超参数对模型容量的影响

|    超参数    | 超参数如何变化使得容量增加 |                             原因                             |                           注意事项                           |
| :----------: | :------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| 隐藏单元数量 |            增加            |              增加隐藏单元数量会增加模型表示能力              | 几乎模型每个操作需要的时间和内存代价都会随隐藏单元数量的增加而增加 |
|    学习率    |          调至最优          | 不正确的学习率，不管高或低，都会由于优化失败而导致低有效容量的模型 |                                                              |
|  卷积核宽度  |            增加            |              增加卷积核宽度会增加模型的参数数量              | 较宽的卷积核导致较窄的输出尺寸，除非使用隐式零填充减少此影响，否则会降低模型的容量。较宽的卷积核需要更多的内存存储参数，并会增加运行时间，但较窄的输出会降低内存代价。 |
|  隐式零填充  |            增加            |        在卷积之前添加隐式零填充能保持大尺寸的输出表示        |                    增加运行时间和内存代价                    |
| 权重衰减系数 |            降低            |              降低可以使得模型参数可以自由地变大              |                                                              |
| Dropout比率  |            降低            |     较少地丢弃单元可以更多地让单元彼此“协力”来适应训练集     |                                                              |

手动调整超参数时，不要忘记最终目标：提升测试集性能。加入正则化只是实现这个目标的一种方法。只要训练误差低，随时都可以通过收集更多的数据来减少泛化误差。实践中能够确保学习有效的暴力方法就是不断提高模型容量和训练集大小，指导解决问题。这种做法增加了训练和推断计算的代价。

#### 11.4.2 自动超参数优化算法

不太建议进行自动超参数优化。

#### 11.4.3 网格搜索



#### 11.4.4 随机搜索

可以用来代替网格搜索，并且编程简单，使用方便，能更快地收敛到超参数的良好取值。

### 11.5 调试策略

由于各种原因，机器学习系统很难调试。在大多数情况下，我们不能知道算法的行为。事实上，使用机器学习的整个出发点就是让机器发现一些人类无法察觉的有用的行为。

另一个难点是，大部分机器学习模型有多个自适应的部分。如果一个部分失效了，其他部分仍然可以自适应，并获得大致可接受的性能。

大部分神经网络的调试策略都是解决这两个难题中的一个或两个。如下为一些重要的调试检测：

- 可视化计算中模型的行为：当训练模型检测图像中的对象时，查看一些模型检测到部分重叠的图像。或者去试听一些生成的语音样本。
- 可视化最严重的错误：可能是预处理或者是标记方式的问题。
- 根据训练和测试误差检测软件：我们往往河南确定底层软件是否正确实现。训练和测试误差能够提供一些线索。如果训练误差低，但是测试误差高，那么很有可能训练过程是在正常运行，但模型由于算法原因过拟合了。或者是因为测试数据和训练数据的预处理的方式不同。
- 拟合极小的数据集：当训练集上有很大误差时，我们需要确定问题是真正的欠拟合还是软件错误。
- 比较反向传播导数和数值导数：



## Chapter 14 自编码器

自编码器是神经网络的一种，经过训练后能尝试将输入复制到输出。自编码器内部有一个隐藏层***h***，可以产生编码表示输入。该网络可以看作由两部分组成：一个由函数$\boldsymbol{h}=f(\boldsymbol{x})$表示的编码器和一个生成重构的解码器$\boldsymbol{r}=g(\boldsymbol{h})$。如果仅仅是将输入复制到输出，输入输出完全相等，则这个自编码器就没什么意义。

事实上，我们应该给自编码器强加一些约束，使它只能近似地复制，并只能近似地复制，并只能复制与训练数据相似的数据。**这些约束强制模型考虑输入数据的哪些部分需要被优先复制，因此它往往能学习到数据的有用特性。**

### 14.1 欠完备自编码器

将输入复制到输出听起来没什么用，但是我们通常不关心解码器的输出，相反，我们希望**通过训练自编码器对输入进行复制使得h获得有用的特性**。

将**h**的维度限制比**x**小，这种编码维度小于输入维度的自编码器成为欠完备自编码器。学习欠完备的表示将强制自编码器捕捉训练数据中最显著的特征。

### 14.2 正则自编码器

隐藏编码的维数大于等于输入维度，称为过完备。

理想情况下，根据要建模的数据分布的复杂性，选择合适的编码维数和编码器、解码器容量，就可以成功训练任意架构的自编码器。正则自编码器提供这样的能力。

正则自编码器使用的损失函数可以鼓励模型学习其他特性（除了将输入复制到输出），而不必限制**使用浅层的编码器和解码器以及小的编码维数来限制模型的容量**。这些特性包括稀疏表示、表示的小导数以及噪声或输入缺失的鲁棒性。

几乎任何带有潜变量并配有一个推断过程（计算给定输入的潜在表示）的生成模型，都可以看作自编码器的一种特殊形式。强调与自编码器联系的两个生成式建模方法是**Helmholtz机**的衍生模型，如变分自编码器，和随机生成网络。这些变种自编码器能够学习出高容量且过完备的模型，进而发现输入数据中有用的结构信息，并且也无须对模型进行正则化。这些模型被训练为**近似训练数据的概率分布而不是将输入复制到输出**。

#### 14.2.1 稀疏自编码器

向代价函数增加一个惩罚项

#### 14.2.2 去噪自编码器

去噪训练过程强制$f$和$g$隐式地学习$p_{data}(\boldsymbol{x})$的结构。因此，去噪自编码器也是一个通过**最小化重构误差获取有用特性的例子**。



### 14.5 去噪自编码器详解



